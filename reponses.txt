Swane NAWAOUI
Enis KULLA

M2PGI
								TP Introduction Hadoop

1.1 Execution d'un modele

	1.
		* map input records correspond au nombre de couples <cle,valeur> en entree de map.
		* map output records correspond au nombre de couples <cle,valeur> en sortie de map.
		
	2.
		* reduce input records correspond:
			- soit au nombre de couples <cle,valeur> produit par map en l'absence de combiner.
			- soit au nombre de couples <cle,valeur> produit par combine.
			
		
	3.
		* Apres un map, un traitement consistent à regrouper toutes les valeurs d'une même clé est effectué.
		Le reduce qui suit le map utilise les couples <cle,liste(valeurs)> produit lors du traitement intermediaire.
		reduce input groups correspond au nombre de groupes ainsi calculé (le nombre de clé sans doublon). 
	
1.2 Premier contact avec HDFS

	* Question:
	
		Chemin vers le reperetoire personnel dans HDFS = /user/<nom_user> (avec hdfs dfs -ls /user)
		Dans notre cas /user/kullae (différent du chemin vers le repertoire personnel local).
		
1.3 Execution sur le cluster

	* Question:
	
		5 splits ou blocs sont lu sur HDFS, 1 pour chacun des 5 tomes des miserables.
		Le compteur "number of splits" indique cette valeur.
	
1.4 Combiner

	1.
		* Les compteurs "Combine input records" et "Combine output records" indiquent le nombre de
		couples <clé, valeur> en entrée et sortie du combiner.
		
	2.
		* Dans le cas des 5 tomes des misérables, l'utilisation du combiner divise
		le nombre de données à traiter pour les reducers d'un facteur à peu prés égal à 4.
		On retrouve ce facteur sur la quantité de données écrite sur le disk en sortie de map (compteur "Map output materialized bytes"):
				--> 6750655 bytes sans combiner
				--> 1645046 bytes avec combiner

	3.
		* Il y a deux façons de connaitre le mot le plus utilisé:
			- en se servant du fait que hadoop renvoi un résultat trié par clé
			et donc en modifiant le reducer de wordcount. Au lieu définir le mot
			comme étant la clé, on choisit la somme.
			
			- avec la commande unix: sort -r -n -k 2 <fichier_resultat>
			
			Le premier couple <clé,valeur> indiqué en resultat et le mot le plus utilisé i.e
			"de" avec un total d'occurences de 16757.
			
1.5 Nombre de reducers

	* Question:
	
		* Chaque reducer génére indépendemment un fichier résultat. Une fois que les mappers finissent
		de s'éxécuter, il n y a plus de raison de synchroniser les reducers qui étaient en attente du
		regroupement des clés. Chaque reducer peut gérer une ou un groupe de clé indépendemment des autres.
		Comme on a fixé le nombre de reducers à 3, on retrouve 3 fichiers résultats dans le répértoire.
		
		La politique de partitionnement Hadoop explique pourquoi il n y a qu'un seul reducer dans le cas
		ou ne spécifie pas explicitement le nombre de reducers à éxécuter.
		Par défaut, Hadoop en ajoute autant qu'il le juge utile.

1.6 In-Mapper Combiner
	
	* L'utilisation du In-Mapper permet de gagner en rapidité grâce à la bufferisation des données mais regroupe
	deux opérations différente en une, ce qui peut nuir à la lisibilité du code pour une application plus complexe.
	
1.7 Compteur

	* Le rapport hadoop nous affiche dans une nouvelle section le compteur définit dans l'application et sa valeur.

2.1 Map et Reduce

	* code
	
2.2 Combiner
	
	* Question:
	
		* Dans le cas d'un combiner, il faudrait utiliser une structure de données contenant:
			- 1 champ pour le tag de type TEXT
			- 1 champ pour le nombre d'occurence de type LONG
			
		Le map retournerait donc un couple clé valeur avec:
			- la clé étant l'identifiant du pays
			- la valeur étant la structure de données i.e les tags et leurs nombre d'occurences
			
		* Les 5 tags les plus utilisés en France sont:
			- france avec 563 occurences
			- spain avec 113 occurences
			- europe avec 75 occurences
			- españa avec 70 occurences
			- bretagne avec 67 occurences
			
		* Ne connaissant pas a priori la taille de la structure (la HashMap), un processus peut essayer
		d'utiliser plus de resources que disponible. Une exception OutOfMemory devrait être
		levé à l'éxécution.
		
3 - Top-tag Flickr par pays, avec tri Hadoop

	* Question préliminaire
	
		Les deux jobs ont chacun une fonctions particuliére:
			- le premier compte le nombre d'occurence des tags par pays.
			- le second s'occupe de trier le resultat et de récupérer le top K uniquement.
			
		Les mappers et reducers de chaque job se comporteront de la façon suivante:
			- pour le premier job:
				+ Map: <Cle, valeur> -> <{Pays, Tag}, Frequence>
				
				Le mapper parse le fichier d'entrée puis associe à chaque clé {Pays, Tag} la fréquence du tag.
				
				+ Reducer: <{Pays, Tag}, Frequence> -> <{Pays, Tag}, Frequence>
				
				Le reducer somme les frequences pour chaque clé {Pays, Tag}.
				
				A ce niveau on a associé la fréquence de tag pour chaque clé {Pays, Tag}.
				Il reste donc à trier les données ainsi obtenu afin d'avoir un resultat trié par pays puis tag et enfin le top k.
				
			- pour le deuxième job:
				+ Map: <{Pays, Tag}, Frequence> -> <{Pays, Frequence}, Tag>
				
				Le mapper ne fait que restructurer les données pour le trie qui se produira juste avant les reduces.
				
				Un premier trie effectué par Hadoop a lieu à l'issue du mapper mais le framework nous permet de définir
				une nouvelle passe qui va nous permettre de parametrer le trie des données.
				On indiquera dans un premier temps comment les valeurs seront distribuées aux reducers ('Grouping' par pays) puis la façon dont les
				couples <clé, valeur> seront triés ('Sort' par pays puis par frequence).
				
				+ Reducer: <{Pays, Frequence}, Tag> -> <{Pays, Tag}, Frequence>
				
				Le reducer récupére un ensemble de données complétement trié.
				Les k-premieres valeurs du reducer correspondent au top k du pays définit dans la clé.
				
3.1 Passes Map Reduce en chaîne

	* Question:

		* Cas ex aequo:
		
			La partie shuffle and sort entre le map et le reduce se fait en même temps. Des qu'un map se termine,
			les clés sont envoyées au reducer en position trié puis groupées.
			Comme rien ne nous garantit qu'un map se termine avant un autre et que le sort n'est pas réeffectué à l'issu d'un reduce,
			l'ordre des clés est potentiellement différent d'une execution à une autre.